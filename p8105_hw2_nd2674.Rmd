---
title: "Homework 1"
author: Nikhita Damaraju
output: github_document
---

This is my solution to Homework 2.

Library imports

```{r}
library(tidyverse)
library(readxl)
```


# Problem 1

Read the Mr. Trashwheel dataset

```{r}
trashwheel_df =
  read_xlsx(
    "./hw2_datasets/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),   
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean 2017 and 2018 precipitation data

```{r}
precip_2017 =
  read_xlsx(
    "./hw2_datasets/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)

precip_2018 =
  read_xlsx(
    "./hw2_datasets/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
```

Combining annual precipitation

```{r}
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2017, precip_2018)

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. The dataset contains information on year, month, and the type of trash collected. There are a total of `r nrow(trashwheel_df)` rows in the dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

# Problem 2

Read the NYC Transit data

```{r}
transit_df =
  read_csv("./hw2_datasets/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES","TRUE", "FALSE"),
         entry = as.logical(entry)
  )
```

The dataset contains information about various trains in NYC and the stations each train transits through. Variables of importance include, stations, geographical coordinates of stations, route number and names along with entry information. So far, the dataset has been filtered to include 19 variables of importance and entry has been changed into a logical variable. There are `r nrow(transit_df)` rows x `r ncol(transit_df)` columns in the dataset.


Reformat route number and name as distinct variables

```{r}
transit_df = 
  transit_df %>% 
  mutate_at(vars(matches("route")), replace_na, 'None') %>%
  mutate_at(vars(matches("route")),as.character())

transit_tidy_df = 
  pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_name",
    values_to = "route_number"
  )

## cleaning up route number by removing None values 
transit_tidy_df = filter(transit_tidy_df, route_number != "None")
```

# Problem 3

Reading datasets of interest in FiveThirtyEight data

```{r}
## creating variable for month names and numbers

month_df =
  tibble(
    month_number = 01:12,
    month = month.name,
    month_abb = month.abb
  )

## reading pol dataset

pols_df =
  read_csv("./hw2_datasets/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month_number", "day"), sep = "-" ) %>%
  mutate(month_number = as.integer(month_number), year = as.integer(year), day = as.integer(day))

## adding month name to pols based on month number 

pols_df = 
  left_join(pols_df, month_df, by = "month_number") %>%
  mutate(
    president = case_when(
      prez_gop != 0 ~ "gop",
      prez_dem != 0 ~ "dem"
    )
  ) %>%
  select(-c(day, month_number, prez_gop, prez_dem, month_abb)) %>%
  relocate(year, month)

## Adding from snp dataset

snp_df =
  read_csv("./hw2_datasets/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month_number", "day", "year"), sep = "/" ) %>%
  mutate(month_number = as.integer(month_number), year = as.integer(year), day = as.integer(day)) 

## Adding month names to snp dataset

snp_df = 
  left_join(snp_df, month_df, by = "month_number") %>% 
  select(-c(month_abb, month_number, day)) %>%
  relocate(year,month)

## reading unemployment dataset

unemployment_df =
  read_csv("./hw2_datasets/fivethirtyeight_datasets/unemployment.csv")  %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "percentage"
  ) 

## adding month name and cleaning 

unemployment_df = 
  left_join(unemployment_df, month_df, by = "month_abb") %>% 
  select(-c(month_abb, month_number)) %>%
  relocate(Year,month) %>%
  janitor::clean_names()
```

Joining datasets

```{r}
combine_df = left_join(pols_df, snp_df, by = c("year", "month"))

final_merged_df = left_join(combine_df, unemployment_df, by = c("year", "month"))
```

There were three datasets in this problem namely pols, snp and unemployment. Dataset pols contained whether a national politician was republican or democratic at a given time. Snp contains variables related to S&P's stock market index at a given time. Unemployment contains the unemployment percentages for each month in each year. The final merged dataset consists of all the three datasets merged according to their month and year. It gives an idea of how the unemployment percentages and stock market index correlate with the president at the time.
